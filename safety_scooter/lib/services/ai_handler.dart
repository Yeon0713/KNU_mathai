import 'package:camera/camera.dart';
import 'package:flutter_vision/flutter_vision.dart';
import 'package:get/get.dart'; 
import '../controllers/settings_controller.dart'; 
import 'byte_track.dart';

class AiHandler {
  late FlutterVision _vision;
  late ByteTracker _tracker;
  bool isLoaded = false;
  
  int _frameCount = 0; // í”„ë ˆì„ ì¹´ìš´í„°
  final int _inferenceInterval = 3; // 3í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆ ì¶”ë¡  (ë‚˜ë¨¸ì§€ëŠ” ì˜ˆì¸¡)

  AiHandler() {
    _vision = FlutterVision();
    _tracker = ByteTracker();
  }

  Future<void> loadModel({String? modelPath}) async {
    try {
      await _vision.loadYoloModel(
        modelPath: modelPath ?? 'assets/models/model.tflite', 
        labels: 'assets/models/labels.txt',             
        modelVersion: "yolov11", 
        numThreads: 2,
        useGpu: true,
      );
      isLoaded = true;
      print("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì„±ê³µ!");
    } catch (e) {
      print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: $e");
    }
  }

  // 2. ëª¨ë¸ êµì²´ í•¨ìˆ˜ (í•µì‹¬ ìˆ˜ì •)
  Future<void> switchModel({required bool toHelmetModel}) async { // toHelmetModel: true -> í—¬ë©§ ëª¨ë¸, false -> ì¼ë°˜ ëª¨ë¸
    // ê¸°ì¡´ ëª¨ë¸ ë‹«ê¸° (ë©”ëª¨ë¦¬ í•´ì œ)
    await _vision.closeYoloModel();
    isLoaded = false;
    _tracker = ByteTracker(); // ëª¨ë¸ì´ ë°”ë€Œë©´ íŠ¸ë˜ì»¤ë„ ë¦¬ì…‹

    // toHelmetModel í”Œë˜ê·¸ì— ë”°ë¼ ëª¨ë¸ ê²½ë¡œ ê²°ì •
    // ì°¸ê³ : í—¬ë©§ ê°ì§€ìš© YOLO ëª¨ë¸ê³¼ ë ˆì´ë¸” íŒŒì¼ì´ assets/models/ í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    // ì˜ˆ: 'assets/models/helmet_yolo.tflite', 'assets/models/helmet_yolo_labels.txt'
    final modelPath = toHelmetModel 
        ? 'assets/models/beom_two_model.tflite' // í—¬ë©§ ê°ì§€ ëª¨ë¸ ê²½ë¡œ (ê°€ì •)
        : 'assets/models/model.tflite';      // ì¼ë°˜ ê°ì²´ ê°ì§€ ëª¨ë¸ ê²½ë¡œ
    final labelsPath = toHelmetModel
        ? 'assets/models/beom_labels.txt' // í—¬ë©§ ë ˆì´ë¸” íŒŒì¼ ê²½ë¡œ (ê°€ì •)
        : 'assets/models/labels.txt';

    print("ğŸ”„ ëª¨ë¸ êµì²´ë¥¼ ì‹œë„í•©ë‹ˆë‹¤: $modelPath");

    try {
      await _vision.loadYoloModel(
        modelPath: modelPath,
        labels: labelsPath,
        modelVersion: "yolov11",
        numThreads: 2,
        useGpu: true,
      );
      isLoaded = true;
      print("âœ… YOLO ëª¨ë¸ êµì²´ ë° ë¡œë“œ ì„±ê³µ!");
    } catch (e) {
      print("âŒ ëª¨ë¸ êµì²´ ì‹¤íŒ¨: $e");
      print("â„¹ï¸ í—¬ë©§ ê°ì§€ ëª¨ë¸ê³¼ ë ˆì´ë¸” íŒŒì¼ì´ 'assets/models/' í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.");
    }
  }

  // 3. ì¶”ë¡  ì‹¤í–‰
  Future<List<Map<String, dynamic>>> runInference(CameraImage cameraImage) async {
    if (!isLoaded) return [];

    double myThreshold = 0.5;
    if (Get.isRegistered<SettingsController>()) {
      myThreshold = Get.find<SettingsController>().confThreshold.value;
    }

    _frameCount++;

    try {
      if (_frameCount % _inferenceInterval == 0) {
        final results = await _vision.yoloOnFrame(
          bytesList: cameraImage.planes.map((plane) => plane.bytes).toList(),
          imageHeight: cameraImage.height,
          imageWidth: cameraImage.width,
          iouThreshold: 0.4,
          confThreshold: 0.1, // ByteTrackì„ ìœ„í•´ ë‚®ì€ ê°’ ìœ ì§€
          classThreshold: 0.1,
        );
        return _tracker.update(results, myThreshold);
      } else {
        return _tracker.updateWithoutDetection();
      }
    } catch (e) {
      print("AI ì¶”ë¡  ì—ëŸ¬: $e");
      return [];
    }
  }

  Future<void> closeModel() async {
    await _vision.closeYoloModel();
  }
}
